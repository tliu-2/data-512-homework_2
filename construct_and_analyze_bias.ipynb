{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Analyzing Bias in Data\n",
    "This notebook provides code that was used to assemble the necessary datasets to examine total articles per capita and high quality articles per capita as well as its corresponding analysis."
   ],
   "id": "c663a1ce1f251805"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Import Necessary Packages\n",
    "For making the API calls we import `request`. For handling the API return objects we use a combination of `pandas` and `polars` to convert them to dataframe objects."
   ],
   "id": "6f2a5432d6309ae9"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-15T03:00:31.736096400Z",
     "start_time": "2024-10-15T03:00:28.619278600Z"
    }
   },
   "source": [
    "# Imports\n",
    "import json, time, urllib.parse\n",
    "import requests\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "# from rapidfuzz import process, fuzz"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Constants\n",
    "The following code was provided by Dr. David McDonald from the University of Washington under the [CC-BY](https://creativecommons.org/licenses/by/4.0/) license."
   ],
   "id": "eddd69a5dfcc9670"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T03:00:31.757879100Z",
     "start_time": "2024-10-15T03:00:31.742754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ORES CONSTANTS:\n",
    "#    The current LiftWing ORES API endpoint and prediction model\n",
    "#\n",
    "API_ORES_LIFTWING_ENDPOINT = \"https://api.wikimedia.org/service/lw/inference/v1/models/{model_name}:predict\"\n",
    "API_ORES_EN_QUALITY_MODEL = \"enwiki-articlequality\"\n",
    "\n",
    "#\n",
    "#    The throttling rate is a function of the Access token that you are granted when you request the token. The constants\n",
    "#    come from dissecting the token and getting the rate limits from the granted token. An example of that is below.\n",
    "#\n",
    "API_LATENCY_ASSUMED_ORES = 0.002     # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT_ORES = ((60.0*60.0)/5000.0)-API_LATENCY_ASSUMED_ORES  # The key authorizes 5000 requests per hour\n",
    "\n",
    "#    When making automated requests we should include something that is unique to the person making the request\n",
    "#    This should include an email - your UW email would be good to put in there\n",
    "#    \n",
    "#    Because all LiftWing API requests require some form of authentication, you need to provide your access token\n",
    "#    as part of the header too\n",
    "#\n",
    "REQUEST_HEADER_TEMPLATE = {\n",
    "    'User-Agent': \"<{email_address}>, University of Washington, MSDS DATA 512 - AUTUMN 2024\",\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': \"Bearer {access_token}\"\n",
    "}\n",
    "#\n",
    "#    This is a template for the parameters that we need to supply in the headers of an API request\n",
    "#\n",
    "REQUEST_HEADER_PARAMS_TEMPLATE = {\n",
    "    'email_address' : \"\",         # your email address should go here\n",
    "    'access_token'  : \"\"          # the access token you create will need to go here\n",
    "}\n",
    "\n",
    "#\n",
    "#    A dictionary of English Wikipedia article titles (keys) and sample revision IDs that can be used for this ORES scoring example\n",
    "#\n",
    "ARTICLE_REVISIONS = { 'Bison':1085687913 , 'Northern flicker':1086582504 , 'Red squirrel':1083787665 , 'Chinook salmon':1085406228 , 'Horseshoe bat':1060601936 }\n",
    "\n",
    "#\n",
    "#    This is a template of the data required as a payload when making a scoring request of the ORES model\n",
    "#\n",
    "ORES_REQUEST_DATA_TEMPLATE = {\n",
    "    \"lang\":        \"en\",     # required that its english - we're scoring English Wikipedia revisions\n",
    "    \"rev_id\":      \"\",       # this request requires a revision id\n",
    "    \"features\":    True\n",
    "}\n",
    "\n",
    "# WP Constants:\n",
    "API_ENWIKIPEDIA_ENDPOINT = \"https://en.wikipedia.org/w/api.php\"\n",
    "API_HEADER_AGENT = 'User-Agent'\n",
    "\n",
    "# We'll assume that there needs to be some throttling for these requests - we should always be nice to a free data resource\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
    "\n",
    "# When making automated requests we should include something that is unique to the person making the request\n",
    "# This should include an email - your UW email would be good to put in there\n",
    "REQUEST_HEADERS = {\n",
    "    'User-Agent': '<tliu2@uw.edu>, University of Washington, MSDS DATA 512 - AUTUMN 2024'\n",
    "}\n",
    "\n",
    "# This is just a list of English Wikipedia article titles that we can use for example requests\n",
    "ARTICLE_TITLES = [ 'Bison', 'Northern flicker', 'Red squirrel', 'Chinook salmon', 'Horseshoe bat' ]\n",
    "\n",
    "# This is a string of additional page properties that can be returned see the Info documentation for\n",
    "# what can be included. If you don't want any this can simply be the empty string\n",
    "PAGEINFO_EXTENDED_PROPERTIES = \"talkid|url|watched|watchers\"\n",
    "#PAGEINFO_EXTENDED_PROPERTIES = \"\"\n",
    "\n",
    "# This template lists the basic parameters for making this\n",
    "PAGEINFO_PARAMS_TEMPLATE = {\n",
    "    \"action\": \"query\",\n",
    "    \"format\": \"json\",\n",
    "    \"titles\": \"\",           # to simplify this should be a single page title at a time\n",
    "    \"prop\": \"info\",\n",
    "    \"inprop\": PAGEINFO_EXTENDED_PROPERTIES\n",
    "}\n",
    "\n",
    "#\n",
    "#    These are used later - defined here so they, at least, have empty values\n",
    "#\n",
    "USERNAME = \"\"\n",
    "ACCESS_TOKEN = \"\"\n",
    "#"
   ],
   "id": "cb9ea88d69b55541",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## API Keys Manager\n",
    "The following code was provided by Dr. David McDonald from the University of Washington under the [CC-BY](https://creativecommons.org/licenses/by/4.0/) license."
   ],
   "id": "f8d9738c49937390"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T21:48:02.854379Z",
     "start_time": "2024-10-13T21:48:02.836548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# API Key\n",
    "from apikeys.KeyManager import KeyManager\n",
    "keyman = KeyManager()\n",
    "\n",
    "USERNAME = \"cakeymoon\"\n",
    "key_info = keyman.findRecord(USERNAME,API_ORES_LIFTWING_ENDPOINT)\n",
    "ACCESS_TOKEN = key_info[0]['key']\n",
    "print(key_info[0]['description'])\n"
   ],
   "id": "b9df0b92c9863b41",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Functions\n",
    "The funcionts `request_ores_score_per_article` and `request_pageinfo_per_article` were provided by Dr. David McDonald from the University of Washington under the [CC-BY](https://creativecommons.org/licenses/by/4.0/) license."
   ],
   "id": "e52c6ea4836242d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T03:00:31.816180900Z",
     "start_time": "2024-10-15T03:00:31.769954200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Functions:\n",
    "def request_ores_score_per_article(article_revid = None, email_address=None, access_token=None,\n",
    "                                   endpoint_url = API_ORES_LIFTWING_ENDPOINT,\n",
    "                                   model_name = API_ORES_EN_QUALITY_MODEL,\n",
    "                                   request_data = ORES_REQUEST_DATA_TEMPLATE,\n",
    "                                   header_format = REQUEST_HEADER_TEMPLATE,\n",
    "                                   header_params = REQUEST_HEADER_PARAMS_TEMPLATE):\n",
    "\n",
    "    #    Make sure we have an article revision id, email and token\n",
    "    #    This approach prioritizes the parameters passed in when making the call\n",
    "    if article_revid:\n",
    "        request_data['rev_id'] = article_revid\n",
    "    if email_address:\n",
    "        header_params['email_address'] = email_address\n",
    "    if access_token:\n",
    "        header_params['access_token'] = access_token\n",
    "\n",
    "    #   Making a request requires a revision id - an email address - and the access token\n",
    "    if not request_data['rev_id']:\n",
    "        raise Exception(\"Must provide an article revision id (rev_id) to score articles\")\n",
    "    if not header_params['email_address']:\n",
    "        raise Exception(\"Must provide an 'email_address' value\")\n",
    "    if not header_params['access_token']:\n",
    "        raise Exception(\"Must provide an 'access_token' value\")\n",
    "\n",
    "    # Create the request URL with the specified model parameter - default is a article quality score request\n",
    "    request_url = endpoint_url.format(model_name=model_name)\n",
    "\n",
    "    # Create a compliant request header from the template and the supplied parameters\n",
    "    headers = dict()\n",
    "    for key in header_format.keys():\n",
    "        headers[str(key)] = header_format[key].format(**header_params)\n",
    "\n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free data\n",
    "        # source like ORES - or other community sources\n",
    "        if API_THROTTLE_WAIT_ORES > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT_ORES)\n",
    "        #response = requests.get(request_url, headers=headers)\n",
    "        response = requests.post(request_url, headers=headers, data=json.dumps(request_data))\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n",
    "\n",
    "\n",
    "\n",
    "def request_pageinfo_per_article(article_title = None,\n",
    "                                 endpoint_url = API_ENWIKIPEDIA_ENDPOINT,\n",
    "                                 request_template = PAGEINFO_PARAMS_TEMPLATE,\n",
    "                                 headers = REQUEST_HEADERS):\n",
    "\n",
    "    # article title can be as a parameter to the call or in the request_template\n",
    "    if article_title:\n",
    "        request_template['titles'] = article_title\n",
    "\n",
    "    if not request_template['titles']:\n",
    "        raise Exception(\"Must supply an article title to make a pageinfo request.\")\n",
    "\n",
    "    if API_HEADER_AGENT not in headers:\n",
    "        raise Exception(f\"The header data should include a '{API_HEADER_AGENT}' field that contains your UW email address.\")\n",
    "\n",
    "    if 'uwnetid@uw' in headers[API_HEADER_AGENT]:\n",
    "        raise Exception(f\"Use your UW email address in the '{API_HEADER_AGENT}' field.\")\n",
    "\n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free\n",
    "        # data source like Wikipedia - or any other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(endpoint_url, headers=headers, params=request_template)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n",
    "\n",
    "\n",
    "def get_closest_region_or_world(country, hierarchy, population_geographies):\n",
    "    if country in population_geographies:  # If the country is already in the pop df then direct match\n",
    "        return country\n",
    "    elif country in hierarchy:  # Else seacrh the dictionary for the next lowest region\n",
    "        region = hierarchy[country]\n",
    "        return region if region in population_geographies else 'WORLD'\n",
    "    else:  # otherwise set it to WORLD\n",
    "        return 'WORLD'\n"
   ],
   "id": "d78582515f241f06",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Intermediary File Assembly\n",
    "To analyze our data, we will need to pull page details and their quality from the Wikimedia API and ORES API.\n",
    "There are just over 7000 pages in our list of pages - so we will call the APIs once and store them into an intermediate csv file which we can load.\n",
    "\n",
    "We first load in the files that contain pages and regions we are interestred in."
   ],
   "id": "8174d7c8cf15bf47"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T03:00:31.890764100Z",
     "start_time": "2024-10-15T03:00:31.786267600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "polit_df = pl.read_csv('./data/politicians_by_country_AUG.2024.csv')\n",
    "pop_df = pl.read_csv('./data/population_by_country_AUG.2024.csv')\n",
    "\n",
    "print(pop_df.head(n=5))"
   ],
   "id": "140e77a785236797",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 2)\n",
      "┌─────────────────┬────────────┐\n",
      "│ Geography       ┆ Population │\n",
      "│ ---             ┆ ---        │\n",
      "│ str             ┆ f64        │\n",
      "╞═════════════════╪════════════╡\n",
      "│ WORLD           ┆ 8009.0     │\n",
      "│ AFRICA          ┆ 1453.0     │\n",
      "│ NORTHERN AFRICA ┆ 256.0      │\n",
      "│ Algeria         ┆ 46.8       │\n",
      "│ Egypt           ┆ 105.2      │\n",
      "└─────────────────┴────────────┘\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We assemble the dataset that contains the page details for each politician.\n",
    "First we get a list of all the unique politicians in our source data and pass each person one-by-one to the Wikimedia API.\n",
    "We then take what the API returns and form it into a dataframe."
   ],
   "id": "826b0ac6a20b2be2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get a list of unique politicians to pull page data on.\n",
    "politician_list = polit_df.unique(subset=['name']).select('name').sort(by='name').to_series().to_list()\n",
    "\n",
    "df_list = []\n",
    "counter = 1\n",
    "invalid_counter = 0\n",
    "invalid_articles = []\n",
    "total_politicians = len(politician_list)\n",
    "\n",
    "# Iterate through each person in the list and call the API.\n",
    "for person in politician_list:\n",
    "    print(f'At article: {person}, {counter} / {total_politicians} articles.')\n",
    "    json_dump = request_pageinfo_per_article(person)\n",
    "    temp_data = json_dump['query']['pages']\n",
    "    page_id = list(temp_data.keys())[0]  # Get the page id\n",
    "    print(f'Page ID for {person}: {page_id}')\n",
    "    if page_id == '-1':  # If api returns invalid page info defined with pageid == -1\n",
    "        invalid_counter += 1\n",
    "        invalid_articles.append(person)\n",
    "        pass\n",
    "    else:\n",
    "        page_info = temp_data[page_id]\n",
    "    \n",
    "        df = pd.DataFrame({\n",
    "            \"pageid\": [page_info[\"pageid\"]],\n",
    "            \"ns\": [page_info[\"ns\"]],\n",
    "            \"title\": [page_info[\"title\"]],\n",
    "            \"contentmodel\": [page_info[\"contentmodel\"]],\n",
    "            \"pagelanguage\": [page_info[\"pagelanguage\"]],\n",
    "            \"pagelanguagehtmlcode\": [page_info[\"pagelanguagehtmlcode\"]],\n",
    "            \"pagelanguagedir\": [page_info[\"pagelanguagedir\"]],\n",
    "            \"touched\": [page_info[\"touched\"]],\n",
    "            \"lastrevid\": [page_info[\"lastrevid\"]],\n",
    "            \"length\": [page_info[\"length\"]],\n",
    "            \"watchers\": [page_info.get(\"watchers\", None)], \n",
    "            \"talkid\": [page_info.get(\"talkid\", None)],  \n",
    "            \"fullurl\": [page_info[\"fullurl\"]],\n",
    "            \"editurl\": [page_info[\"editurl\"]],\n",
    "            \"canonicalurl\": [page_info[\"canonicalurl\"]]\n",
    "        })\n",
    "        df_list.append(df)\n",
    "    counter += 1\n",
    "\n",
    "print(f'Number of invalid articles: {invalid_counter}')\n",
    "print(f'Invalid Articles: {invalid_articles}')\n",
    "final_df = pd.concat(df_list)\n",
    "\n",
    "# Store the dataframe for future use.\n",
    "final_df.to_csv('./politician_page_data.csv', index=False, encoding='utf-8-sig')\n",
    "    \n",
    "\n",
    "print(polit_df.head(n=5))\n",
    "print(pop_df.head(n=5))"
   ],
   "id": "78d011c635cdec95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Using our page data we previously pulled, get the revision ids and pass them to the ORES API one-by-one.\n",
    "With the API return, convert it to a dataframe format.\n",
    "\n",
    "We transform the API data into a dataframe format and store it."
   ],
   "id": "702889edcdf888cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load in the politician page data csv we generated in the previous step and select the relevant columns.\n",
    "wp_page_data = pl.read_csv('./politician_page_data.csv', infer_schema_length=int(1e10))\n",
    "wp_page_data = wp_page_data.select('pageid', 'title', 'lastrevid')\n",
    "print(wp_page_data.head(n=5))\n",
    "\n",
    "# Get a list of unique revids to pull from the ORES API.\n",
    "revids = wp_page_data.select('lastrevid').unique().sort(by='lastrevid').to_series().to_list()\n",
    "counter = 1\n",
    "invalid_counter = 0\n",
    "invalid_articles = []\n",
    "df_list = []\n",
    "total_ids = len(revids)\n",
    "\n",
    "# Iterate through the list of revids.\n",
    "for id in revids:\n",
    "    print(f'At id: {id}, {counter} / {total_ids} ids.')\n",
    "\n",
    "    while True:\n",
    "        try:  # Try a API pull.\n",
    "            score = request_ores_score_per_article(article_revid=id,\n",
    "                                                   email_address=\"tliu2@uw.edu\",\n",
    "                                                   access_token=ACCESS_TOKEN)\n",
    "    \n",
    "            revid = list(score[\"enwiki\"][\"scores\"].keys())[0]\n",
    "            break  # If it works, break the While loop.\n",
    "        except KeyError:  # If accessing 'enwiki' throws a Key Error, something has gone wrong.\n",
    "            code = score['httpCode']\n",
    "            print(f'failed revid: {revid}')\n",
    "            print(score)\n",
    "            print('retrying...')\n",
    "            # Keep trying until it works.\n",
    "            if code == 429:\n",
    "                time.sleep(10)\n",
    "            else:\n",
    "                time.sleep(5)\n",
    "\n",
    "    \n",
    "    # Transform the data into a dataframe format.\n",
    "    articlequality = score[\"enwiki\"][\"scores\"][revid][\"articlequality\"][\"score\"]\n",
    "    prediction = articlequality[\"prediction\"]\n",
    "    probabilities = articlequality[\"probability\"]\n",
    "    data = {\n",
    "        \"revid\": [revid],\n",
    "        \"prediction\": [prediction],\n",
    "        **{f\"probability_{k}\": [v] for k, v in probabilities.items()}\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df_list.append(df)\n",
    "    counter += 1\n",
    "    \n",
    "final = pd.concat(df_list)\n",
    "# Output it - use utf-8 as there are some special characters.\n",
    "final.to_csv('./articlequality.csv', index=False, encoding='utf-8-sig')\n"
   ],
   "id": "ae479539bb760f6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Analysis - Preprocess\n",
    "Now that we have the data we need from the APIs, we must create the merged dataset which has columns:\n",
    "- country\n",
    "- region\n",
    "- population\n",
    "- article_title\n",
    "- revision_id\n",
    "- article_quality\n",
    "\n",
    "We'll load in our intermediate files we generated and pull the columns we need from each and merge on article title.\n",
    "\n",
    "In the original source files of population and politician by region, there are inconsistencies with how a country / region is named.\n",
    "For example, South Korea may appear as Korea, South or Korea (South). For us to properly merge these sets, we'll need to handle these edge cases.\n"
   ],
   "id": "8403aeff26398dc4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T01:53:14.377291700Z",
     "start_time": "2024-10-15T01:53:14.306615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "manual_mapping = {\n",
    "    'Korea, South': 'Korea (South)',\n",
    "    'Korea, North': 'Korea (North)',\n",
    "    'Bosnia Herzegovina': 'Bosnia and Herzegovina',\n",
    "    'Timor Leste': 'Timor-Leste',\n",
    "    \"Cote d'Ivoire\": 'Côte d’Ivoire',\n",
    "    'Myanmar': 'Burma',\n",
    "    'GuineaBissau': 'Guinea-Bissau'\n",
    "}\n",
    "pop_df = pop_df.with_columns(\n",
    "    pl.col('Geography').replace_strict(manual_mapping, default=pl.col('Geography'))\n",
    ")\n",
    "# Load in page data.\n",
    "polit_page_df = pl.read_csv('./data/politician_page_data.csv', infer_schema_length=int(1e10)).rename({'lastrevid': 'revid'})\n",
    "quality_df = pl.read_csv('./data/articlequality.csv', infer_schema_length=int(1e10))\n",
    "\n",
    "# Merge page info with ORES data.\n",
    "merged_df = polit_page_df.join(\n",
    "    quality_df, on=['revid'], how='full', coalesce=True\n",
    ")\n",
    "merged_df = merged_df.select('pageid', 'title', 'revid', 'prediction')\n",
    "\n",
    "# Hierarchy merge\n",
    "pop_df = pop_df.to_pandas()\n",
    "polit_df = polit_df.to_pandas()\n",
    "\n",
    "pop_df['is_region'] = pop_df['Geography'].str.isupper()\n",
    "# Ffill regions downwards to link country with its next hierarchical region.\n",
    "pop_df['region'] = pop_df['Geography'].where(pop_df['is_region']).ffill()\n",
    "\n",
    "# Filter only the rows where the Geography column is a country and not a REGION.\n",
    "country_region_mapping = pop_df[~pop_df['is_region']][['Geography', 'region']]\n",
    "\n",
    "hierarchy = dict(zip(country_region_mapping['Geography'], country_region_mapping['region']))\n",
    "\n",
    "population_geographies = set(pop_df['Geography'])\n",
    "polit_df['region_match'] = polit_df['country'].apply(\n",
    "    lambda x: get_closest_region_or_world(x, hierarchy, population_geographies)\n",
    ")\n",
    "pop_df = pl.from_pandas(pop_df)\n",
    "polit_df = pl.from_pandas(polit_df)\n",
    "\n",
    "pop_polit = polit_df.join(\n",
    "    pop_df,\n",
    "    left_on='region_match', right_on='Geography', how='left'\n",
    ")\n",
    "\n",
    "# Merge with the original source data on pop and polit by country\n",
    "merged_df = merged_df.join(\n",
    "    pop_polit.rename({'name': 'title'}), on=['title'], how='full', coalesce=True\n",
    ")\n",
    "print(merged_df.head(n=5))\n",
    "merged_df = merged_df.select('country', 'region_match', 'Population', 'title', 'revid', 'prediction')\n",
    "merged_df = merged_df.rename({\n",
    "    'region_match': 'region', 'title': 'article_title', 'revid': 'revision_id', 'prediction': 'article_quality', 'Population': 'population'\n",
    "})\n",
    "\n",
    "print(merged_df.sort(by='article_title').head(n=5))\n",
    "print(merged_df.sort(by='article_title', nulls_last=True).head(n=5))\n"
   ],
   "id": "2b98b840461183cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 10)\n",
      "┌──────────┬────────────┬────────────┬────────────┬───┬───────────┬───────────┬───────────┬────────┐\n",
      "│ pageid   ┆ title      ┆ revid      ┆ prediction ┆ … ┆ region_ma ┆ Populatio ┆ is_region ┆ region │\n",
      "│ ---      ┆ ---        ┆ ---        ┆ ---        ┆   ┆ tch       ┆ n         ┆ ---       ┆ ---    │\n",
      "│ i64      ┆ str        ┆ i64        ┆ str        ┆   ┆ ---       ┆ ---       ┆ bool      ┆ str    │\n",
      "│          ┆            ┆            ┆            ┆   ┆ str       ┆ f64       ┆           ┆        │\n",
      "╞══════════╪════════════╪════════════╪════════════╪═══╪═══════════╪═══════════╪═══════════╪════════╡\n",
      "│ 10483286 ┆ Majah Ha   ┆ 1233202991 ┆ Start      ┆ … ┆ Afghanist ┆ 42.4      ┆ false     ┆ SOUTH  │\n",
      "│          ┆ Adrif      ┆            ┆            ┆   ┆ an        ┆           ┆           ┆ ASIA   │\n",
      "│ 11966231 ┆ Haroon     ┆ 1230459615 ┆ B          ┆ … ┆ Afghanist ┆ 42.4      ┆ false     ┆ SOUTH  │\n",
      "│          ┆ al-Afghani ┆            ┆            ┆   ┆ an        ┆           ┆           ┆ ASIA   │\n",
      "│ 46841383 ┆ Tayyab     ┆ 1225661708 ┆ Start      ┆ … ┆ Afghanist ┆ 42.4      ┆ false     ┆ SOUTH  │\n",
      "│          ┆ Agha       ┆            ┆            ┆   ┆ an        ┆           ┆           ┆ ASIA   │\n",
      "│ 71600382 ┆ Khadija    ┆ 1234741562 ┆ Stub       ┆ … ┆ Afghanist ┆ 42.4      ┆ false     ┆ SOUTH  │\n",
      "│          ┆ Zahra      ┆            ┆            ┆   ┆ an        ┆           ┆           ┆ ASIA   │\n",
      "│          ┆ Ahmadi     ┆            ┆            ┆   ┆           ┆           ┆           ┆        │\n",
      "│ 47805901 ┆ Aziza      ┆ 1195651393 ┆ Start      ┆ … ┆ Afghanist ┆ 42.4      ┆ false     ┆ SOUTH  │\n",
      "│          ┆ Ahmadyar   ┆            ┆            ┆   ┆ an        ┆           ┆           ┆ ASIA   │\n",
      "└──────────┴────────────┴────────────┴────────────┴───┴───────────┴───────────┴───────────┴────────┘\n",
      "shape: (5, 6)\n",
      "┌───────────┬───────────┬────────────┬──────────────────────────┬─────────────┬─────────────────┐\n",
      "│ country   ┆ region    ┆ population ┆ article_title            ┆ revision_id ┆ article_quality │\n",
      "│ ---       ┆ ---       ┆ ---        ┆ ---                      ┆ ---         ┆ ---             │\n",
      "│ str       ┆ str       ┆ f64        ┆ str                      ┆ i64         ┆ str             │\n",
      "╞═══════════╪═══════════╪════════════╪══════════════════════════╪═════════════╪═════════════════╡\n",
      "│ Iraq      ┆ Iraq      ┆ 45.5       ┆ 'Abd al-Razzaq al-Hasani ┆ 1238643436  ┆ Start           │\n",
      "│ Slovenia  ┆ Slovenia  ┆ 2.1        ┆ 8th National Assembly of ┆ 1249160149  ┆ C               │\n",
      "│           ┆           ┆            ┆ Slove…                   ┆             ┆                 │\n",
      "│ Sri Lanka ┆ Sri Lanka ┆ 22.7       ┆ A. J. R. de Soysa        ┆ 1187003494  ┆ Start           │\n",
      "│ Guyana    ┆ Guyana    ┆ 0.8        ┆ A. R. F. Webber          ┆ 1156355955  ┆ Start           │\n",
      "│ Indonesia ┆ Indonesia ┆ 278.7      ┆ A. Wahab                 ┆ 1213828687  ┆ Stub            │\n",
      "└───────────┴───────────┴────────────┴──────────────────────────┴─────────────┴─────────────────┘\n",
      "shape: (5, 6)\n",
      "┌───────────┬───────────┬────────────┬──────────────────────────┬─────────────┬─────────────────┐\n",
      "│ country   ┆ region    ┆ population ┆ article_title            ┆ revision_id ┆ article_quality │\n",
      "│ ---       ┆ ---       ┆ ---        ┆ ---                      ┆ ---         ┆ ---             │\n",
      "│ str       ┆ str       ┆ f64        ┆ str                      ┆ i64         ┆ str             │\n",
      "╞═══════════╪═══════════╪════════════╪══════════════════════════╪═════════════╪═════════════════╡\n",
      "│ Iraq      ┆ Iraq      ┆ 45.5       ┆ 'Abd al-Razzaq al-Hasani ┆ 1238643436  ┆ Start           │\n",
      "│ Slovenia  ┆ Slovenia  ┆ 2.1        ┆ 8th National Assembly of ┆ 1249160149  ┆ C               │\n",
      "│           ┆           ┆            ┆ Slove…                   ┆             ┆                 │\n",
      "│ Sri Lanka ┆ Sri Lanka ┆ 22.7       ┆ A. J. R. de Soysa        ┆ 1187003494  ┆ Start           │\n",
      "│ Guyana    ┆ Guyana    ┆ 0.8        ┆ A. R. F. Webber          ┆ 1156355955  ┆ Start           │\n",
      "│ Indonesia ┆ Indonesia ┆ 278.7      ┆ A. Wahab                 ┆ 1213828687  ┆ Stub            │\n",
      "└───────────┴───────────┴────────────┴──────────────────────────┴─────────────┴─────────────────┘\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T01:53:21.140952600Z",
     "start_time": "2024-10-15T01:53:21.120794700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get no direct matches\n",
    "matches_df = pop_df.join(\n",
    "    polit_df, left_on=['Geography'], right_on=['country'], how='full'\n",
    ")\n",
    "\n",
    "no_matches = matches_df.filter(\n",
    "    (pl.col('region').is_null()) | (pl.col('country').is_null())\n",
    ")\n",
    "no_matches = no_matches.with_columns(\n",
    "    pl.col('country').fill_null(pl.col('region'))\n",
    ").select('country').unique().to_series().sort().to_list()\n",
    "\n",
    "with open('./data/wp_countries-no_match.txt', 'w', encoding='utf-8-sig') as f:\n",
    "    for line in no_matches:\n",
    "        f.write(f\"{line}\\n\")\n",
    "        \n",
    "matches_df = merged_df.filter(\n",
    "    (pl.col('region').is_not_null()) & (pl.col('country').is_not_null())\n",
    ")\n",
    "matches_df.write_csv('./data/wp_politicians_by_country.csv', include_bom=True)"
   ],
   "id": "13d1cb8effad7214",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Analysis\n",
    "With our final dataset assembled, we can begin our analysis.\n",
    "\n",
    "We will specifically be looking for 6 things:\n",
    "1. Top 10 countries by coverage.\n",
    "    - The 10 countries with highest total articles per capita (in descending order).\n",
    "2. Bottom 10 countries by coverage.\n",
    "    - The 10 countries with lowest total articles per capita (in descending order).\n",
    "3. Top 10 countries by high quality\n",
    "    - The 10 countries with highest high quality articles per capita (in descending order).\n",
    "4. Bottom 10 countries by high quality.\n",
    "    - The 10 countries with the lowest high quality articles per capita (in ascending order).\n",
    "5. Geographic regions by total coverage.\n",
    "    - A rank ordered list of geographic regions (in descending order) by total articles per capita.\n",
    "6. Geographic regions by high quality coverage.\n",
    "    - Rank ordered list of geographic regions (in descending order) by high quality articles per capita.\n",
    "\n",
    "We define a \"high quality\" article to be that has `article_quality` of \"FA\" (featured article) or \"GA\" (good article).\n",
    "\n",
    "In the population dataset, there are some countries that have a population of 0. For the sake of this analysis, we will be removing these countries as we cannot calculate accurate per capita calculations for countries that have 0 population.\n",
    "Examples of countries with 0 population are Monaco and Tuvalu.\n"
   ],
   "id": "899bd0452d8e46da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T03:00:42.586569100Z",
     "start_time": "2024-10-15T03:00:42.546483700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pl.read_csv('./data/wp_politicians_by_country.csv', infer_schema_length=int(1e10))\n",
    "df = df.filter(pl.col('population') != 0)\n",
    "high_quality = ['FA', 'GA']\n"
   ],
   "id": "e5e16fb11a2586c9",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T03:05:04.546304900Z",
     "start_time": "2024-10-15T03:05:04.481127600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Per Capita Calculations\n",
    "df = df.with_columns(\n",
    "    pl.col('population') * 1_000_000\n",
    ")\n",
    "\n",
    "country_df = df.group_by(['country']).agg(\n",
    "    pl.col('article_title').count().alias('total_articles'),\n",
    "    pl.col('article_quality').is_in(high_quality).sum().alias('high_quality_articles'),\n",
    "    pl.col('population').max().alias('population')\n",
    ")\n",
    "\n",
    "country_df = country_df.with_columns(\n",
    "    (pl.col('total_articles') / pl.col('population')).alias('articles_per_capita'),\n",
    "    (pl.col('high_quality_articles') / pl.col('population')).alias('high_quality_articles_per_capita'),\n",
    ")\n",
    "\n",
    "country_df = country_df.sort(by=['country'])\n",
    "\n",
    "# 1. Top 10 countries by coverage\n",
    "top10_coverage = country_df.top_k(10, by='articles_per_capita').sort(by='articles_per_capita', descending=True)\n",
    "print('1. Top 10 Countries By Coverage')\n",
    "display(top10_coverage)\n",
    "\n",
    "# 2. Bottom 10 countries by coverage\n",
    "bottom10_coverage = country_df.bottom_k(10, by='articles_per_capita').sort(by='articles_per_capita', descending=True)\n",
    "print('2. Bottom 10 Countries By Coverage')\n",
    "display(bottom10_coverage)\n",
    "\n",
    "# 3. Top 10 countries by high quality\n",
    "top10_quality = country_df.top_k(10, by='high_quality_articles_per_capita').sort(by='high_quality_articles_per_capita', descending=True)\n",
    "print('3. Top 10 Countries By Quality')\n",
    "display(top10_quality)\n",
    "\n",
    "# 4. Bottom 10 countries by high quality\n",
    "bottom10_quality = country_df.bottom_k(10, by='high_quality_articles_per_capita').sort(by='high_quality_articles_per_capita', descending=True)\n",
    "print('4. Bottom 10 Countries By Quality')\n",
    "display(bottom10_quality)"
   ],
   "id": "4c50f21210360f0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Top 10 Countries By Coverage\n"
     ]
    },
    {
     "data": {
      "text/plain": "shape: (10, 6)\n┌─────────────┬────────────────┬──────────────────┬────────────┬─────────────────┬─────────────────┐\n│ country     ┆ total_articles ┆ high_quality_art ┆ population ┆ articles_per_ca ┆ high_quality_ar │\n│ ---         ┆ ---            ┆ icles            ┆ ---        ┆ pita            ┆ ticles_per_capi │\n│ str         ┆ u32            ┆ ---              ┆ f64        ┆ ---             ┆ …               │\n│             ┆                ┆ u32              ┆            ┆ f64             ┆ ---             │\n│             ┆                ┆                  ┆            ┆                 ┆ f64             │\n╞═════════════╪════════════════╪══════════════════╪════════════╪═════════════════╪═════════════════╡\n│ Antigua and ┆ 33             ┆ 0                ┆ 1.0000e17  ┆ 3.3000e-16      ┆ 0.0             │\n│ Barbuda     ┆                ┆                  ┆            ┆                 ┆                 │\n│ Federated   ┆ 14             ┆ 0                ┆ 1.0000e17  ┆ 1.4000e-16      ┆ 0.0             │\n│ States of   ┆                ┆                  ┆            ┆                 ┆                 │\n│ Micronesia  ┆                ┆                  ┆            ┆                 ┆                 │\n│ Marshall    ┆ 13             ┆ 0                ┆ 1.0000e17  ┆ 1.3000e-16      ┆ 0.0             │\n│ Islands     ┆                ┆                  ┆            ┆                 ┆                 │\n│ Tonga       ┆ 10             ┆ 0                ┆ 1.0000e17  ┆ 1.0000e-16      ┆ 0.0             │\n│ Barbados    ┆ 25             ┆ 0                ┆ 3.0000e17  ┆ 8.3333e-17      ┆ 0.0             │\n│ Montenegro  ┆ 36             ┆ 3                ┆ 6.0000e17  ┆ 6.0000e-17      ┆ 5.0000e-18      │\n│ Seychelles  ┆ 6              ┆ 0                ┆ 1.0000e17  ┆ 6.0000e-17      ┆ 0.0             │\n│ Bhutan      ┆ 44             ┆ 0                ┆ 8.0000e17  ┆ 5.5000e-17      ┆ 0.0             │\n│ Maldives    ┆ 33             ┆ 1                ┆ 6.0000e17  ┆ 5.5000e-17      ┆ 1.6667e-18      │\n│ Samoa       ┆ 8              ┆ 0                ┆ 2.0000e17  ┆ 4.0000e-17      ┆ 0.0             │\n└─────────────┴────────────────┴──────────────────┴────────────┴─────────────────┴─────────────────┘",
      "text/html": "<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (10, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>country</th><th>total_articles</th><th>high_quality_articles</th><th>population</th><th>articles_per_capita</th><th>high_quality_articles_per_capita</th></tr><tr><td>str</td><td>u32</td><td>u32</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Antigua and Barbuda&quot;</td><td>33</td><td>0</td><td>1.0000e17</td><td>3.3000e-16</td><td>0.0</td></tr><tr><td>&quot;Federated States of Micronesia&quot;</td><td>14</td><td>0</td><td>1.0000e17</td><td>1.4000e-16</td><td>0.0</td></tr><tr><td>&quot;Marshall Islands&quot;</td><td>13</td><td>0</td><td>1.0000e17</td><td>1.3000e-16</td><td>0.0</td></tr><tr><td>&quot;Tonga&quot;</td><td>10</td><td>0</td><td>1.0000e17</td><td>1.0000e-16</td><td>0.0</td></tr><tr><td>&quot;Barbados&quot;</td><td>25</td><td>0</td><td>3.0000e17</td><td>8.3333e-17</td><td>0.0</td></tr><tr><td>&quot;Montenegro&quot;</td><td>36</td><td>3</td><td>6.0000e17</td><td>6.0000e-17</td><td>5.0000e-18</td></tr><tr><td>&quot;Seychelles&quot;</td><td>6</td><td>0</td><td>1.0000e17</td><td>6.0000e-17</td><td>0.0</td></tr><tr><td>&quot;Bhutan&quot;</td><td>44</td><td>0</td><td>8.0000e17</td><td>5.5000e-17</td><td>0.0</td></tr><tr><td>&quot;Maldives&quot;</td><td>33</td><td>1</td><td>6.0000e17</td><td>5.5000e-17</td><td>1.6667e-18</td></tr><tr><td>&quot;Samoa&quot;</td><td>8</td><td>0</td><td>2.0000e17</td><td>4.0000e-17</td><td>0.0</td></tr></tbody></table></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Bottom 10 Countries By Coverage\n"
     ]
    },
    {
     "data": {
      "text/plain": "shape: (10, 6)\n┌───────────────┬────────────────┬─────────────────┬────────────┬─────────────────┬────────────────┐\n│ country       ┆ total_articles ┆ high_quality_ar ┆ population ┆ articles_per_ca ┆ high_quality_a │\n│ ---           ┆ ---            ┆ ticles          ┆ ---        ┆ pita            ┆ rticles_per_ca │\n│ str           ┆ u32            ┆ ---             ┆ f64        ┆ ---             ┆ pi…            │\n│               ┆                ┆ u32             ┆            ┆ f64             ┆ ---            │\n│               ┆                ┆                 ┆            ┆                 ┆ f64            │\n╞═══════════════╪════════════════╪═════════════════╪════════════╪═════════════════╪════════════════╡\n│ Côte d’Ivoire ┆ 10             ┆ 0               ┆ 3.0900e19  ┆ 3.2362e-19      ┆ 0.0            │\n│ Egypt         ┆ 32             ┆ 1               ┆ 1.0520e20  ┆ 3.0418e-19      ┆ 9.5057e-21     │\n│ Israel        ┆ 2              ┆ 0               ┆ 9.8000e18  ┆ 2.0408e-19      ┆ 0.0            │\n│ Norway        ┆ 1              ┆ 0               ┆ 5.5000e18  ┆ 1.8182e-19      ┆ 0.0            │\n│ Zambia        ┆ 3              ┆ 0               ┆ 2.0200e19  ┆ 1.4851e-19      ┆ 0.0            │\n│ Saudi Arabia  ┆ 5              ┆ 2               ┆ 3.6900e19  ┆ 1.3550e-19      ┆ 5.4201e-20     │\n│ Ghana         ┆ 4              ┆ 1               ┆ 3.4100e19  ┆ 1.1730e-19      ┆ 2.9326e-20     │\n│ India         ┆ 151            ┆ 0               ┆ 1.4286e21  ┆ 1.0570e-19      ┆ 0.0            │\n│ China         ┆ 16             ┆ 0               ┆ 1.4113e21  ┆ 1.1337e-20      ┆ 0.0            │\n│ Korean        ┆ 56             ┆ 3               ┆ 8.0090e21  ┆ 6.9921e-21      ┆ 3.7458e-22     │\n└───────────────┴────────────────┴─────────────────┴────────────┴─────────────────┴────────────────┘",
      "text/html": "<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (10, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>country</th><th>total_articles</th><th>high_quality_articles</th><th>population</th><th>articles_per_capita</th><th>high_quality_articles_per_capita</th></tr><tr><td>str</td><td>u32</td><td>u32</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Côte d’Ivoire&quot;</td><td>10</td><td>0</td><td>3.0900e19</td><td>3.2362e-19</td><td>0.0</td></tr><tr><td>&quot;Egypt&quot;</td><td>32</td><td>1</td><td>1.0520e20</td><td>3.0418e-19</td><td>9.5057e-21</td></tr><tr><td>&quot;Israel&quot;</td><td>2</td><td>0</td><td>9.8000e18</td><td>2.0408e-19</td><td>0.0</td></tr><tr><td>&quot;Norway&quot;</td><td>1</td><td>0</td><td>5.5000e18</td><td>1.8182e-19</td><td>0.0</td></tr><tr><td>&quot;Zambia&quot;</td><td>3</td><td>0</td><td>2.0200e19</td><td>1.4851e-19</td><td>0.0</td></tr><tr><td>&quot;Saudi Arabia&quot;</td><td>5</td><td>2</td><td>3.6900e19</td><td>1.3550e-19</td><td>5.4201e-20</td></tr><tr><td>&quot;Ghana&quot;</td><td>4</td><td>1</td><td>3.4100e19</td><td>1.1730e-19</td><td>2.9326e-20</td></tr><tr><td>&quot;India&quot;</td><td>151</td><td>0</td><td>1.4286e21</td><td>1.0570e-19</td><td>0.0</td></tr><tr><td>&quot;China&quot;</td><td>16</td><td>0</td><td>1.4113e21</td><td>1.1337e-20</td><td>0.0</td></tr><tr><td>&quot;Korean&quot;</td><td>56</td><td>3</td><td>8.0090e21</td><td>6.9921e-21</td><td>3.7458e-22</td></tr></tbody></table></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Top 10 Countries By Quality\n"
     ]
    },
    {
     "data": {
      "text/plain": "shape: (10, 6)\n┌─────────────┬────────────────┬──────────────────┬────────────┬─────────────────┬─────────────────┐\n│ country     ┆ total_articles ┆ high_quality_art ┆ population ┆ articles_per_ca ┆ high_quality_ar │\n│ ---         ┆ ---            ┆ icles            ┆ ---        ┆ pita            ┆ ticles_per_capi │\n│ str         ┆ u32            ┆ ---              ┆ f64        ┆ ---             ┆ …               │\n│             ┆                ┆ u32              ┆            ┆ f64             ┆ ---             │\n│             ┆                ┆                  ┆            ┆                 ┆ f64             │\n╞═════════════╪════════════════╪══════════════════╪════════════╪═════════════════╪═════════════════╡\n│ Montenegro  ┆ 36             ┆ 3                ┆ 6.0000e17  ┆ 6.0000e-17      ┆ 5.0000e-18      │\n│ Luxembourg  ┆ 27             ┆ 2                ┆ 7.0000e17  ┆ 3.8571e-17      ┆ 2.8571e-18      │\n│ Albania     ┆ 70             ┆ 7                ┆ 2.7000e18  ┆ 2.5926e-17      ┆ 2.5926e-18      │\n│ Kosovo      ┆ 26             ┆ 4                ┆ 1.7000e18  ┆ 1.5294e-17      ┆ 2.3529e-18      │\n│ Maldives    ┆ 33             ┆ 1                ┆ 6.0000e17  ┆ 5.5000e-17      ┆ 1.6667e-18      │\n│ Lithuania   ┆ 58             ┆ 4                ┆ 2.9000e18  ┆ 2.0000e-17      ┆ 1.3793e-18      │\n│ Croatia     ┆ 65             ┆ 5                ┆ 3.8000e18  ┆ 1.7105e-17      ┆ 1.3158e-18      │\n│ Guyana      ┆ 17             ┆ 1                ┆ 8.0000e17  ┆ 2.1250e-17      ┆ 1.2500e-18      │\n│ Palestinian ┆ 61             ┆ 6                ┆ 5.5000e18  ┆ 1.1091e-17      ┆ 1.0909e-18      │\n│ Territory   ┆                ┆                  ┆            ┆                 ┆                 │\n│ Slovenia    ┆ 38             ┆ 2                ┆ 2.1000e18  ┆ 1.8095e-17      ┆ 9.5238e-19      │\n└─────────────┴────────────────┴──────────────────┴────────────┴─────────────────┴─────────────────┘",
      "text/html": "<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (10, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>country</th><th>total_articles</th><th>high_quality_articles</th><th>population</th><th>articles_per_capita</th><th>high_quality_articles_per_capita</th></tr><tr><td>str</td><td>u32</td><td>u32</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Montenegro&quot;</td><td>36</td><td>3</td><td>6.0000e17</td><td>6.0000e-17</td><td>5.0000e-18</td></tr><tr><td>&quot;Luxembourg&quot;</td><td>27</td><td>2</td><td>7.0000e17</td><td>3.8571e-17</td><td>2.8571e-18</td></tr><tr><td>&quot;Albania&quot;</td><td>70</td><td>7</td><td>2.7000e18</td><td>2.5926e-17</td><td>2.5926e-18</td></tr><tr><td>&quot;Kosovo&quot;</td><td>26</td><td>4</td><td>1.7000e18</td><td>1.5294e-17</td><td>2.3529e-18</td></tr><tr><td>&quot;Maldives&quot;</td><td>33</td><td>1</td><td>6.0000e17</td><td>5.5000e-17</td><td>1.6667e-18</td></tr><tr><td>&quot;Lithuania&quot;</td><td>58</td><td>4</td><td>2.9000e18</td><td>2.0000e-17</td><td>1.3793e-18</td></tr><tr><td>&quot;Croatia&quot;</td><td>65</td><td>5</td><td>3.8000e18</td><td>1.7105e-17</td><td>1.3158e-18</td></tr><tr><td>&quot;Guyana&quot;</td><td>17</td><td>1</td><td>8.0000e17</td><td>2.1250e-17</td><td>1.2500e-18</td></tr><tr><td>&quot;Palestinian Territory&quot;</td><td>61</td><td>6</td><td>5.5000e18</td><td>1.1091e-17</td><td>1.0909e-18</td></tr><tr><td>&quot;Slovenia&quot;</td><td>38</td><td>2</td><td>2.1000e18</td><td>1.8095e-17</td><td>9.5238e-19</td></tr></tbody></table></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Bottom 10 Countries By Quality\n"
     ]
    },
    {
     "data": {
      "text/plain": "shape: (10, 6)\n┌─────────────┬────────────────┬──────────────────┬────────────┬─────────────────┬─────────────────┐\n│ country     ┆ total_articles ┆ high_quality_art ┆ population ┆ articles_per_ca ┆ high_quality_ar │\n│ ---         ┆ ---            ┆ icles            ┆ ---        ┆ pita            ┆ ticles_per_capi │\n│ str         ┆ u32            ┆ ---              ┆ f64        ┆ ---             ┆ …               │\n│             ┆                ┆ u32              ┆            ┆ f64             ┆ ---             │\n│             ┆                ┆                  ┆            ┆                 ┆ f64             │\n╞═════════════╪════════════════╪══════════════════╪════════════╪═════════════════╪═════════════════╡\n│ Kuwait      ┆ 17             ┆ 0                ┆ 4.4000e18  ┆ 3.8636e-18      ┆ 0.0             │\n│ Antigua and ┆ 33             ┆ 0                ┆ 1.0000e17  ┆ 3.3000e-16      ┆ 0.0             │\n│ Barbuda     ┆                ┆                  ┆            ┆                 ┆                 │\n│ Bahamas     ┆ 9              ┆ 0                ┆ 4.0000e17  ┆ 2.2500e-17      ┆ 0.0             │\n│ Barbados    ┆ 25             ┆ 0                ┆ 3.0000e17  ┆ 8.3333e-17      ┆ 0.0             │\n│ Belize      ┆ 9              ┆ 0                ┆ 5.0000e17  ┆ 1.8000e-17      ┆ 0.0             │\n│ Benin       ┆ 7              ┆ 0                ┆ 1.3700e19  ┆ 5.1095e-19      ┆ 0.0             │\n│ Bhutan      ┆ 44             ┆ 0                ┆ 8.0000e17  ┆ 5.5000e-17      ┆ 0.0             │\n│ Botswana    ┆ 3              ┆ 0                ┆ 2.7000e18  ┆ 1.1111e-18      ┆ 0.0             │\n│ Cape Verde  ┆ 9              ┆ 0                ┆ 6.0000e17  ┆ 1.5000e-17      ┆ 0.0             │\n│ Chad        ┆ 21             ┆ 0                ┆ 1.8300e19  ┆ 1.1475e-18      ┆ 0.0             │\n└─────────────┴────────────────┴──────────────────┴────────────┴─────────────────┴─────────────────┘",
      "text/html": "<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (10, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>country</th><th>total_articles</th><th>high_quality_articles</th><th>population</th><th>articles_per_capita</th><th>high_quality_articles_per_capita</th></tr><tr><td>str</td><td>u32</td><td>u32</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Kuwait&quot;</td><td>17</td><td>0</td><td>4.4000e18</td><td>3.8636e-18</td><td>0.0</td></tr><tr><td>&quot;Antigua and Barbuda&quot;</td><td>33</td><td>0</td><td>1.0000e17</td><td>3.3000e-16</td><td>0.0</td></tr><tr><td>&quot;Bahamas&quot;</td><td>9</td><td>0</td><td>4.0000e17</td><td>2.2500e-17</td><td>0.0</td></tr><tr><td>&quot;Barbados&quot;</td><td>25</td><td>0</td><td>3.0000e17</td><td>8.3333e-17</td><td>0.0</td></tr><tr><td>&quot;Belize&quot;</td><td>9</td><td>0</td><td>5.0000e17</td><td>1.8000e-17</td><td>0.0</td></tr><tr><td>&quot;Benin&quot;</td><td>7</td><td>0</td><td>1.3700e19</td><td>5.1095e-19</td><td>0.0</td></tr><tr><td>&quot;Bhutan&quot;</td><td>44</td><td>0</td><td>8.0000e17</td><td>5.5000e-17</td><td>0.0</td></tr><tr><td>&quot;Botswana&quot;</td><td>3</td><td>0</td><td>2.7000e18</td><td>1.1111e-18</td><td>0.0</td></tr><tr><td>&quot;Cape Verde&quot;</td><td>9</td><td>0</td><td>6.0000e17</td><td>1.5000e-17</td><td>0.0</td></tr><tr><td>&quot;Chad&quot;</td><td>21</td><td>0</td><td>1.8300e19</td><td>1.1475e-18</td><td>0.0</td></tr></tbody></table></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T03:05:44.125548Z",
     "start_time": "2024-10-15T03:05:44.069571400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Region Calculations\n",
    "region_df = df.group_by(['region']).agg(\n",
    "    pl.col('article_title').count().alias('total_articles'),\n",
    "    pl.col('article_quality').is_in(high_quality).sum().alias('high_quality_articles'),\n",
    "    pl.col('population').sum().alias('population')\n",
    ").sort(by=['region'])\n",
    "\n",
    "region_df = region_df.with_columns(\n",
    "    (pl.col('total_articles') / pl.col('population')).alias('articles_per_capita'),\n",
    "    (pl.col('high_quality_articles') / pl.col('population')).alias('high_quality_articles_per_capita'),\n",
    ")\n",
    "\n",
    "regions_by_cover = region_df.sort(by='articles_per_capita', descending=True)\n",
    "regions_by_quality = region_df.sort(by='high_quality_articles_per_capita', descending=True)\n",
    "\n",
    "print('5. Regions by Total Coverage')\n",
    "display(regions_by_cover)\n",
    "\n",
    "print('6. Regions by Quality')\n",
    "display(regions_by_quality)"
   ],
   "id": "3336664fa8f3a8ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. Regions by Total Coverage\n"
     ]
    },
    {
     "data": {
      "text/plain": "shape: (167, 6)\n┌─────────────┬────────────────┬──────────────────┬────────────┬─────────────────┬─────────────────┐\n│ region      ┆ total_articles ┆ high_quality_art ┆ population ┆ articles_per_ca ┆ high_quality_ar │\n│ ---         ┆ ---            ┆ icles            ┆ ---        ┆ pita            ┆ ticles_per_capi │\n│ str         ┆ u32            ┆ ---              ┆ f64        ┆ ---             ┆ …               │\n│             ┆                ┆ u32              ┆            ┆ f64             ┆ ---             │\n│             ┆                ┆                  ┆            ┆                 ┆ f64             │\n╞═════════════╪════════════════╪══════════════════╪════════════╪═════════════════╪═════════════════╡\n│ Antigua and ┆ 33             ┆ 0                ┆ 3.3000e18  ┆ 1.0000e-17      ┆ 0.0             │\n│ Barbuda     ┆                ┆                  ┆            ┆                 ┆                 │\n│ Federated   ┆ 14             ┆ 0                ┆ 1.4000e18  ┆ 1.0000e-17      ┆ 0.0             │\n│ States of   ┆                ┆                  ┆            ┆                 ┆                 │\n│ Micronesia  ┆                ┆                  ┆            ┆                 ┆                 │\n│ Grenada     ┆ 2              ┆ 0                ┆ 2.0000e17  ┆ 1.0000e-17      ┆ 0.0             │\n│ Marshall    ┆ 13             ┆ 0                ┆ 1.3000e18  ┆ 1.0000e-17      ┆ 0.0             │\n│ Islands     ┆                ┆                  ┆            ┆                 ┆                 │\n│ Seychelles  ┆ 6              ┆ 0                ┆ 6.0000e17  ┆ 1.0000e-17      ┆ 0.0             │\n│ …           ┆ …              ┆ …                ┆ …          ┆ …               ┆ …               │\n│ Pakistan    ┆ 94             ┆ 4                ┆ 2.2607e22  ┆ 4.1580e-21      ┆ 1.7694e-22      │\n│ Indonesia   ┆ 113            ┆ 15               ┆ 3.1493e22  ┆ 3.5881e-21      ┆ 4.7629e-22      │\n│ China       ┆ 16             ┆ 0                ┆ 2.2581e22  ┆ 7.0857e-22      ┆ 0.0             │\n│ India       ┆ 151            ┆ 0                ┆ 2.1572e23  ┆ 6.9999e-22      ┆ 0.0             │\n│ WORLD       ┆ 56             ┆ 3                ┆ 4.4850e23  ┆ 1.2486e-22      ┆ 6.6889e-24      │\n└─────────────┴────────────────┴──────────────────┴────────────┴─────────────────┴─────────────────┘",
      "text/html": "<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (167, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>region</th><th>total_articles</th><th>high_quality_articles</th><th>population</th><th>articles_per_capita</th><th>high_quality_articles_per_capita</th></tr><tr><td>str</td><td>u32</td><td>u32</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Antigua and Barbuda&quot;</td><td>33</td><td>0</td><td>3.3000e18</td><td>1.0000e-17</td><td>0.0</td></tr><tr><td>&quot;Federated States of Micronesia&quot;</td><td>14</td><td>0</td><td>1.4000e18</td><td>1.0000e-17</td><td>0.0</td></tr><tr><td>&quot;Grenada&quot;</td><td>2</td><td>0</td><td>2.0000e17</td><td>1.0000e-17</td><td>0.0</td></tr><tr><td>&quot;Marshall Islands&quot;</td><td>13</td><td>0</td><td>1.3000e18</td><td>1.0000e-17</td><td>0.0</td></tr><tr><td>&quot;Seychelles&quot;</td><td>6</td><td>0</td><td>6.0000e17</td><td>1.0000e-17</td><td>0.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Pakistan&quot;</td><td>94</td><td>4</td><td>2.2607e22</td><td>4.1580e-21</td><td>1.7694e-22</td></tr><tr><td>&quot;Indonesia&quot;</td><td>113</td><td>15</td><td>3.1493e22</td><td>3.5881e-21</td><td>4.7629e-22</td></tr><tr><td>&quot;China&quot;</td><td>16</td><td>0</td><td>2.2581e22</td><td>7.0857e-22</td><td>0.0</td></tr><tr><td>&quot;India&quot;</td><td>151</td><td>0</td><td>2.1572e23</td><td>6.9999e-22</td><td>0.0</td></tr><tr><td>&quot;WORLD&quot;</td><td>56</td><td>3</td><td>4.4850e23</td><td>1.2486e-22</td><td>6.6889e-24</td></tr></tbody></table></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6. Regions by Quality\n"
     ]
    },
    {
     "data": {
      "text/plain": "shape: (167, 6)\n┌────────────┬────────────────┬──────────────────┬────────────┬──────────────────┬─────────────────┐\n│ region     ┆ total_articles ┆ high_quality_art ┆ population ┆ articles_per_cap ┆ high_quality_ar │\n│ ---        ┆ ---            ┆ icles            ┆ ---        ┆ ita              ┆ ticles_per_capi │\n│ str        ┆ u32            ┆ ---              ┆ f64        ┆ ---              ┆ …               │\n│            ┆                ┆ u32              ┆            ┆ f64              ┆ ---             │\n│            ┆                ┆                  ┆            ┆                  ┆ f64             │\n╞════════════╪════════════════╪══════════════════╪════════════╪══════════════════╪═════════════════╡\n│ Montenegro ┆ 36             ┆ 3                ┆ 2.1600e19  ┆ 1.6667e-18       ┆ 1.3889e-19      │\n│ Luxembourg ┆ 27             ┆ 2                ┆ 1.8900e19  ┆ 1.4286e-18       ┆ 1.0582e-19      │\n│ Kosovo     ┆ 26             ┆ 4                ┆ 4.4200e19  ┆ 5.8824e-19       ┆ 9.0498e-20      │\n│ Gabon      ┆ 5              ┆ 1                ┆ 1.2000e19  ┆ 4.1667e-19       ┆ 8.3333e-20      │\n│ Latvia     ┆ 7              ┆ 1                ┆ 1.3300e19  ┆ 5.2632e-19       ┆ 7.5188e-20      │\n│ …          ┆ …              ┆ …                ┆ …          ┆ …                ┆ …               │\n│ Uzbekistan ┆ 25             ┆ 0                ┆ 9.1000e20  ┆ 2.7473e-20       ┆ 0.0             │\n│ Vanuatu    ┆ 4              ┆ 0                ┆ 1.2000e18  ┆ 3.3333e-18       ┆ 0.0             │\n│ Yemen      ┆ 32             ┆ 0                ┆ 1.1008e21  ┆ 2.9070e-20       ┆ 0.0             │\n│ Zambia     ┆ 3              ┆ 0                ┆ 6.0600e19  ┆ 4.9505e-20       ┆ 0.0             │\n│ Zimbabwe   ┆ 69             ┆ 0                ┆ 1.1523e21  ┆ 5.9880e-20       ┆ 0.0             │\n└────────────┴────────────────┴──────────────────┴────────────┴──────────────────┴─────────────────┘",
      "text/html": "<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (167, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>region</th><th>total_articles</th><th>high_quality_articles</th><th>population</th><th>articles_per_capita</th><th>high_quality_articles_per_capita</th></tr><tr><td>str</td><td>u32</td><td>u32</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Montenegro&quot;</td><td>36</td><td>3</td><td>2.1600e19</td><td>1.6667e-18</td><td>1.3889e-19</td></tr><tr><td>&quot;Luxembourg&quot;</td><td>27</td><td>2</td><td>1.8900e19</td><td>1.4286e-18</td><td>1.0582e-19</td></tr><tr><td>&quot;Kosovo&quot;</td><td>26</td><td>4</td><td>4.4200e19</td><td>5.8824e-19</td><td>9.0498e-20</td></tr><tr><td>&quot;Gabon&quot;</td><td>5</td><td>1</td><td>1.2000e19</td><td>4.1667e-19</td><td>8.3333e-20</td></tr><tr><td>&quot;Latvia&quot;</td><td>7</td><td>1</td><td>1.3300e19</td><td>5.2632e-19</td><td>7.5188e-20</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Uzbekistan&quot;</td><td>25</td><td>0</td><td>9.1000e20</td><td>2.7473e-20</td><td>0.0</td></tr><tr><td>&quot;Vanuatu&quot;</td><td>4</td><td>0</td><td>1.2000e18</td><td>3.3333e-18</td><td>0.0</td></tr><tr><td>&quot;Yemen&quot;</td><td>32</td><td>0</td><td>1.1008e21</td><td>2.9070e-20</td><td>0.0</td></tr><tr><td>&quot;Zambia&quot;</td><td>3</td><td>0</td><td>6.0600e19</td><td>4.9505e-20</td><td>0.0</td></tr><tr><td>&quot;Zimbabwe&quot;</td><td>69</td><td>0</td><td>1.1523e21</td><td>5.9880e-20</td><td>0.0</td></tr></tbody></table></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
